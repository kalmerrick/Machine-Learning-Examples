{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest: Equipment valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning can be distilled down to a couple of key techniques that are of very wide applicability. Recent studies have shown that the vast majority of datasets can be best modeled with just two methods:\n",
    "\n",
    "- *Ensembles of decision trees* (i.e. Random Forests and Gradient Boosting Machines), mainly for structured data (such as you might find in a database table at most companies)\n",
    "- *Multi-layered neural networks learnt with SGD* (i.e. shallow and/or deep learning), mainly for unstructured data (such as audio, vision, and natural language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the contest is to predict the sale price of a particular piece of heavy equiment at auction based on it's usage, equipment type, and configuaration.  The data is sourced from auction result postings and includes information on usage and equipment configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are predicting the sale price of bulldozers sold at auctions. The data is split into three parts:\n",
    "\n",
    "- **Train.csv** is the training set, which contains data through the end of 2011.\n",
    "- **Valid.csv** is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "- **Test.csv** is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
    "\n",
    "The key fields are in train.csv are:\n",
    "\n",
    "- SalesID: the uniue identifier of the sale\n",
    "- MachineID: the unique identifier of a machine.  A machine can be sold multiple times\n",
    "- saleprice: what the machine sold for at auction (only provided in train.csv)\n",
    "- saledate: the date of the sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from structured import *\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/bulldozers/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Kaggle provides info about some of the fields of our dataset; on the [Kaggle Data info](https://www.kaggle.com/c/bluebook-for-bulldozers/data) page they say the following:\n",
    "\n",
    "For this competition, you are predicting the sale price of bulldozers sold at auctions. The data for this competition is split into three parts:\n",
    "\n",
    "- **Train.csv** is the training set, which contains data through the end of 2011.\n",
    "- **Valid.csv** is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "- **Test.csv** is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
    "\n",
    "The key fields are in train.csv are:\n",
    "\n",
    "- SalesID: the uniue identifier of the sale\n",
    "- MachineID: the unique identifier of a machine.  A machine can be sold multiple times\n",
    "- saleprice: what the machine sold for at auction (only provided in train.csv)\n",
    "- saledate: the date of the sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(f'{PATH}Train.csv', low_memory=False, \n",
    "                     parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Important to look at your data**, to make sure you understand the format, how it's stored, what type of values it holds, etc. Even if you've read descriptions about your data, the actual data may not be what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>401120</th>\n",
       "      <th>401121</th>\n",
       "      <th>401122</th>\n",
       "      <th>401123</th>\n",
       "      <th>401124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SalesID</th>\n",
       "      <td>6333336</td>\n",
       "      <td>6333337</td>\n",
       "      <td>6333338</td>\n",
       "      <td>6333341</td>\n",
       "      <td>6333342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>10500</td>\n",
       "      <td>11000</td>\n",
       "      <td>11500</td>\n",
       "      <td>9000</td>\n",
       "      <td>7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MachineID</th>\n",
       "      <td>1840702</td>\n",
       "      <td>1830472</td>\n",
       "      <td>1887659</td>\n",
       "      <td>1903570</td>\n",
       "      <td>1926965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ModelID</th>\n",
       "      <td>21439</td>\n",
       "      <td>21439</td>\n",
       "      <td>21439</td>\n",
       "      <td>21435</td>\n",
       "      <td>21435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasource</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             401120   401121   401122   401123   401124\n",
       "SalesID     6333336  6333337  6333338  6333341  6333342\n",
       "SalePrice     10500    11000    11500     9000     7750\n",
       "MachineID   1840702  1830472  1887659  1903570  1926965\n",
       "ModelID       21439    21439    21439    21435    21435\n",
       "datasource      149      149      149      149      149"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(df_raw.tail().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SalesID</th>\n",
       "      <td>401125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.91971e+06</td>\n",
       "      <td>909021</td>\n",
       "      <td>1.13925e+06</td>\n",
       "      <td>1.41837e+06</td>\n",
       "      <td>1.63942e+06</td>\n",
       "      <td>2.24271e+06</td>\n",
       "      <td>6.33334e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>401125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31099.7</td>\n",
       "      <td>23036.9</td>\n",
       "      <td>4750</td>\n",
       "      <td>14500</td>\n",
       "      <td>24000</td>\n",
       "      <td>40000</td>\n",
       "      <td>142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MachineID</th>\n",
       "      <td>401125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2179e+06</td>\n",
       "      <td>440992</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0887e+06</td>\n",
       "      <td>1.27949e+06</td>\n",
       "      <td>1.46807e+06</td>\n",
       "      <td>2.48633e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ModelID</th>\n",
       "      <td>401125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6889.7</td>\n",
       "      <td>6221.78</td>\n",
       "      <td>28</td>\n",
       "      <td>3259</td>\n",
       "      <td>4604</td>\n",
       "      <td>8724</td>\n",
       "      <td>37198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasource</th>\n",
       "      <td>401125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.666</td>\n",
       "      <td>8.96224</td>\n",
       "      <td>121</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>136</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count unique  top freq first last         mean      std  \\\n",
       "SalesID     401125    NaN  NaN  NaN   NaN  NaN  1.91971e+06   909021   \n",
       "SalePrice   401125    NaN  NaN  NaN   NaN  NaN      31099.7  23036.9   \n",
       "MachineID   401125    NaN  NaN  NaN   NaN  NaN   1.2179e+06   440992   \n",
       "ModelID     401125    NaN  NaN  NaN   NaN  NaN       6889.7  6221.78   \n",
       "datasource  401125    NaN  NaN  NaN   NaN  NaN      134.666  8.96224   \n",
       "\n",
       "                    min          25%          50%          75%          max  \n",
       "SalesID     1.13925e+06  1.41837e+06  1.63942e+06  2.24271e+06  6.33334e+06  \n",
       "SalePrice          4750        14500        24000        40000       142000  \n",
       "MachineID             0   1.0887e+06  1.27949e+06  1.46807e+06  2.48633e+06  \n",
       "ModelID              28         3259         4604         8724        37198  \n",
       "datasource          121          132          132          136          172  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(df_raw.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's important to note what metric is being used for a project. Generally, selecting the metric(s) is an important part of the project setup. However, in this case Kaggle tells us what metric to use: RMSLE (root mean squared log error) between the actual and predicted auction prices. Therefore we take the log of the prices, so that RMSE will give us what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw.SalePrice = np.log(df_raw.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Initial processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This dataset contains a mix of **continuous** and **categorical** variables.\n",
    "\n",
    "The following method extracts particular date fields from a complete datetime for the purpose of constructing categoricals.  You should always consider this feature extraction step when working with date-time. Without expanding your date-time into these additional fields, you can't capture any trend/cyclical behavior as a function of time at any of these granularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2006\n",
       "1    2004\n",
       "2    2004\n",
       "3    2011\n",
       "4    2009\n",
       "Name: saleYear, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_datepart(df_raw, 'saledate')\n",
    "df_raw.saleYear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The categorical variables are currently stored as strings, which is inefficient, and doesn't provide the numeric coding required for a random forest. Therefore we call `train_cats` to convert strings to pandas categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_cats(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can specify the order to use for categorical variables if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['High', 'Low', 'Medium'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.UsageBand.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw.UsageBand.cat.set_categories(['High', 'Medium', 'Low'], ordered=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw.UsageBand = df_raw.UsageBand.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're still not quite done - for instance we have lots of missing values, wish we can't pass directly to a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Backhoe_Mounting    0.803872\n",
       "Blade_Extension     0.937129\n",
       "Blade_Type          0.800977\n",
       "Blade_Width         0.937129\n",
       "Coupler             0.466620\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(df_raw.isnull().sum().sort_index()/len(df_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But let's save this file for now, since it's already in format can we be stored and accessed efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)\n",
    "df_raw.to_feather('tmp/bulldozers-raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the future we can simply read it from this fast format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_feather('tmp/bulldozers-raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll replace categories with their numeric codes, handle missing continuous values, and split the dependent variable into a separate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df, y, nas = proc_df(df_raw, 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now have something we can pass to a random forest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9831884012319884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "m.fit(df, y)\n",
    "m.score(df,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*todo* define r^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Wow, an r^2 of 0.98 - that's great, right? Well, perhaps not...\n",
    "\n",
    "Possibly **the most important idea** in machine learning is that of having separate training & validation data sets. As motivation, suppose you don't divide up your data, but instead use all of it.  And suppose you have lots of parameters:\n",
    "\n",
    "<img src=\"images/overfitting2.png\" alt=\"\" style=\"width: 70%\"/>\n",
    "<center>\n",
    "[Underfitting and Overfitting](https://datascience.stackexchange.com/questions/361/when-is-a-model-underfitted)\n",
    "</center>\n",
    "\n",
    "The error for the pictured data points is lowest for the model on the far right (the blue curve passes through the red points almost perfectly), yet it's not the best choice.  Why is that?  If you were to gather some new data points, they most likely would not be on that curve in the graph on the right, but would be closer to the curve in the middle graph.\n",
    "\n",
    "This illustrates how using all our data can lead to **overfitting**. A validation set helps diagnose this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((389125, 66), (389125,), (12000, 66))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_vals(a,n): return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 12000  # same as Kaggle's test set size\n",
    "n_trn = len(df)-n_valid\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)\n",
    "X_train, X_valid = split_vals(df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our model again, this time with separate training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.3 s\n",
      "[0.09033251172626666, 0.25562237401178006, 0.982946128027757, 0.8833067590462174]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An r^2 in the high-80's isn't bad at all (and the RMSLE puts us around rank 100 of 470 on the Kaggle leaderboard), but we can see from the validation set score that we're over-fitting badly. To understand this issue, let's simplify things down to a single small tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice', subset=30000, na_dict=nas)\n",
    "X_train, _ = split_vals(df_trn, 20000)\n",
    "y_train, _ = split_vals(y_trn, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.76 s\n",
      "[0.11288160852138789, 0.3559170662971735, 0.971943329574702, 0.7737723938433041]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5286376163751128, 0.5790482235052056, 0.3846731329346569, 0.4012059984887952]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we create a bigger tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.756054031998178e-17, 0.5168940897787633, 1.0, 0.5228541983845075]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, bootstrap=False, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set result looks great! But the validation set is worse than our original model. This is why we need to use *bagging* of multiple trees to get more generalizable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about bagging in random forests, let's start with our basic model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11307985828321883, 0.3577950252855737, 0.9718446932659256, 0.7713787632208241]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll grab the predictions for each individual tree, and look at one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.4727 , 9.04782, 9.82553, 9.39266, 9.04782, 9.04782, 9.07681, 9.10498, 9.07681, 9.10498]),\n",
       " 9.21979345750555,\n",
       " 9.104979856318357)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.stack([t.predict(X_valid) for t in m.estimators_])\n",
    "preds[:,0], np.mean(preds[:,0]), y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 12000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29ab5580a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(10)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of this curve suggests that adding more trees isn't going to help us much. Let's check. (Compare this to our original model on a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10137230753106004, 0.3519315411380613, 0.9773729249762403, 0.7788105765282304]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0967601844323646, 0.3382318355421217, 0.9793850100715124, 0.7956959673935099]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09413390127392837, 0.34436715017343394, 0.9804888949238293, 0.7882168482486069]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=80, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-bag (OOB) score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is our validation set worse than our training set because we're over-fitting, or because the validation set is for a different time period, or a bit of both? With the existing information we've shown, we can't tell. However, random forests have a very clever trick called *out-of-bag (OOB) error* which can handle this (and more!)\n",
    "\n",
    "The idea is to calculate error on the training set, but only include the trees in the calculation of a row's error where that row was *not* included in training that tree. This allows us to see whether the model is over-fitting, without needing a separate validation set.\n",
    "\n",
    "This also has the benefit of allowing us to see whether our model generalizes, even if we only have a small amount of data so want to avoid separating some out to create a validation set.\n",
    "\n",
    "This is as simple as adding one more parameter to our model constructor. We print the OOB error last in our `print_score` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09744844147476907, 0.34685875681281514, 0.9790906974200047, 0.7851411235473967, 0.8514160615047317]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our validation set time difference is making an impact, as is model over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that one of the easiest ways to avoid over-fitting is also one of the best ways to speed up analysis: *subsampling*. Let's return to using our full dataset, so that we can demonstrate the impact of this technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')\n",
    "X_train, X_valid = split_vals(df_trn, n_trn)\n",
    "y_train, y_valid = split_vals(y_trn, n_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is this: rather than limit the total amount of data that our model can access, let's instead limit it to a *different* random subset per tree. That way, given enough trees, the model can still see *all* the data, but for each individual tree it'll be just as fast as if we had cut down our dataset as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rf_samples(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.9 s\n",
      "[0.23969981625247636, 0.27523648585454324, 0.8799201246760533, 0.8647117800832601, 0.8675059346574596]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1, oob_score=True)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each additional tree allows the model to see more data, this approach can make additional trees more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22710338326679333, 0.2623387490276293, 0.892209115804136, 0.8770940634461883, 0.8806954767187457]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree building parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We revert to using a full bootstrap sample in order to show the impact of other over-fitting avoidance methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_rf_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a baseline for this full set to compare to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07845801171665845, 0.2378425213520164, 0.9871350109123928, 0.8989754384465173, 0.9083863876039964]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to reduce over-fitting is to grow our trees less deeply. We do this by specifying (with `min_samples_leaf`) that we require some minimum number of rows in every leaf node. This has two benefits:\n",
    "\n",
    "- There are less decision rules for each leaf node; simpler models should generalize better\n",
    "- The predictions are made by averaging more rows in the leaf node, resulting in less volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11517030145929684, 0.23446798792498072, 0.9722785569873039, 0.9018217951034285, 0.908312052174951]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also increase the amount of variation amongst the trees by not only use a sample of rows for each tree, but to also using a sample of *columns* for each *split*. We do this by specifying `max_features`, which is the proportion of features to randomly select from at each split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None\n",
    "- 0.5\n",
    "- 'sqrt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1, 3, 5, 10, 25, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11908101153924065, 0.22863779083394734, 0.9703639815598172, 0.9066436197297091, 0.9116520622002207]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't compare our results directly with the Kaggle competition, since it used a different validation set (and we can no longer to submit to this competition) - but we can at least see that we're getting similar results to the winners based on the dataset we have.\n",
    "\n",
    "The sklearn docs [show an example](http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html) of different `max_features` methods with increasing numbers of trees - as you see, using a subset of features on each split requires using more trees, but results in better models:\n",
    "![sklearn max_features chart](http://scikit-learn.org/stable/_images/sphx_glr_plot_ensemble_oob_001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
